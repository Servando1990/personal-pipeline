{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.width', 100000000)\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input_etl_data.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract three new columns from column via \n",
    "\n",
    "# Change to string and the to json\n",
    "# Preprocess double quotes for json valid format\n",
    "\n",
    "df['via'] = df['via'].apply(lambda row: json.loads(row.replace('“', '\"').replace('”', '\"')))\n",
    "\n",
    "# Extract desired columns\n",
    "\n",
    "df['channel'] = df['via'].apply(lambda row: row['channel'] if 'channel' in row else '')\n",
    "df['address_client'] = df['via'].apply(lambda row: row['source']['from']['address'] if 'address' in row['source']['from'] else '')\n",
    "df['name_client'] = df['via'].apply(lambda row: row['source']['from']['name'] if 'name' in row['source']['from'] else '')\n",
    "\n",
    "# Drop via column\n",
    "df.drop(['via'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import feature_engineering\n",
    "fe = feature_engineering.Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of the week and week of the year column\n",
    "df = fe.datetime_transform(df, 'created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group_des column \n",
    "df.group_id.dtype\n",
    "# Verify data type\n",
    "df['group_id'] = df.group_id.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up conditions\n",
    "conditions = [\n",
    "    (df['group_id'] == 20938601),\n",
    "    (df['group_id'] == 21052033),\n",
    "    (df['group_id'] == 21054107),\n",
    "    (df['group_id'] == 360002394054),\n",
    "    (df['group_id'] == 28479838),\n",
    "    (df['group_id'] == 360002386813),\n",
    "    (df['group_id'] == 21406268)\n",
    "\n",
    "]\n",
    "# set up decode words to match\n",
    "values = ['Soporte', 'Francia', 'Italia', 'EN', 'Portugual', 'DE', 'Postventa']\n",
    "\n",
    "df['group_des'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output_etl_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7593dc81c4c5f89d7c3d0d53e1886cfdbb332bb25fabe84412f35200ebaf024"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('cluster-t')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
